= Match Compilation [110.97 version]
:Author: Dave MacQueen
:Date: 2020/05/09
:stem: latexmath
:source-highlighter: pygments
:VERSION: 110.98

== [1] Introduction

This document describes the revised implementation of the match compiler
SML/NJ 110.98. This document replaces the Alex Aiken compiler note.

== [2] Old Files (in base/compiler/FLINT/trans)
   mcommon.sml    -- match compiler types
   matchcomp.sml  -- the main (or reset of the) match compiler
   translate.sml  -- old translate file, calling match compiler functions

== [3] New Files (in base/compiler/Elaborator/matchcomp)
   mctypes.sml  -- match compiler types (replaces trans/mccommon.sml)
                   defines types key, path, andor, dec-tree, and mcexp
   rules.{sig,sml}
                -- ruleno sets (sets of rule numbers)
   andor.sml    -- construction or the andor tree from pattern list
   decisiontree.sml
                -- constructing a decision tree from andor tree,
   		   decision trees involve only OR nodes
   mcexp.sml    -- concrete abstract syntax of match compiler expressions
   vmcexp.sml   -- virtual implementation of mcexp in terms of Absyn.exp
   mc-code.sml  -- constructing "abstract" match compiler code (mcexp)
                   from rules, andor, and dec-tree for a match
   vcode.sml    -- translating "virtual" mcexp expressions to Absyn
   match.sml    -- top-level matchComp function
   transmc.sml  -- translating typed Absyn into Absyn with compiled matches
 
== [4] Terminology anb basic types

The types used in the match compiler are defined 

- type ruleno = int
   index, zero-based, of a rule in a match
   [OBS] E.g. "allRules" defined in matchComp, which is the list after OR expansion

- type ruleset = ruleno list = int list
   an ordered list of rule indices (no duplicates) representing rule index sets
   Based on BinaryIntMap library (smlnj-lib/Util) module.
   
- type dconinfo = datacon * tyvar list
   [OBS] a dataconstructor (occurring in a pattern) with an "associated"? list of tyvars
   [Q: what is the relation between the datacon and the tyvars?]

- "destructuring paths" (datatype path)
  [OBS: paths that record a position in a decision tree? But paths are _trees_ because
   of the RECORDPATH constructor! ]

=== [5] Two complications in the and-or analysis.

- layered patterns. But the pattern that is layered over a base pattern is
  restricted to be a variable (possibly with at type constraint), so the "information
  content is not modified by a layered pattern. It just introduces a variable
  binding at that node.

- vector patterns. These are _both_ OR (dispatching on the length of the vector)
  and AND in the sense that all the element patterns of the vector pattern must
  be matched.  These two roles could possibly be separated, splitting the node
  into an OR over lengths, and for each 

   case x 
     of #[nil, x::y] => ...
      | #[z::w, nil] => ...

  Here the two patterns are vectors of the same length, but the element patterns
  for OR choices. This case should be analyzed similarly to

   case x 
     of {a = nil, b = x::y} => ...
      | {a = z::w, b = nil} => ...

  where on the "a"-field there is an OR choice on {nil, z::w} and on the "b"-field
  there is an OR choice on {x::y, nil}. But we know (from type-checking} that all
  record patterns at the same node will have the same record type and hence the same
  fields.  So there is no OR choice at the level of the record patterns themselves,
  only at the level of corresponding field patterns, where in this case, both the
  "a"-field and "b"-field give rise to OR choices (which will have to be ordered 
  during the construction of the decision tree).

  But two vector patterns at the same node may be of different lengths:

      case x 
	 of #[nil, x::y] => ...
	  | #[z::w, nil, u] => ...

  Here we do the OR dispatch solely on the vector length, and the respective field
  patterns (here {nil, z::w} for the 1st element) do not constitute an OR choice --
  they are "independent" because they lie in separate OR branches.  This is analagous
  to the following situation:

     datatype t = A of int list * int list
                | B of int list * int list

     case x
       of A(nil,x::y) =>
        | B(z::w,nil) =>

  where we don't dispatch on the {nil, z::w} patterns because the A vs B OR node
  has separated them into two branches.

== [6] And-Or trees

Principles:

- Pattern space (for a type)
  Types are either pattern opaque (atomic) or pattern transparent:

  (1) pattern opaque types are types that are atomic or opaque wrt pattern matching,
      i.e. they cannot be analyzed or deconstructed using pattern matching. 
      These types are function types, abstract types, and primitive types other
      than integers, words, characters and strings. There is, not surprisingly,
      a lot of overlap with "equality" types (types that admit generic equality).

  (2) pattern transparent types are formed by products and sums (datatypes) and
      recursion, plus a small set of primitive types that can match atomic (constant)
      patterns, namely int, word, char, and string types.

Given a pattern-transparent type (pattern type, for short), it can be
unfolded into an infinite (or quasi-infinite, in the case of a
primitive type like int) tree constructed from AND nodes (for
products) and OR nodes for sums. [E.g. infinite (regular) tree for 'a
list.]

A sequence of patterns for a pattern type determines a finite "initial
segment" of the tree for the pattern type. The branches of this initial
tree (the union of the finite branches (paths) in the individual patterns,
is called the pattern spece for the pattern set. The branches are finite and
terminate with (a) atomic variable patterns, or (b) constant patterns, where
a constant can be a constant for a primitive type (e.g. 3) or a constant data
constructor (e.g. true, false, nil).

This is the basic AND-OR tree for the pattern sequence, and it is a concrete 
representation of the pattern space generated by the pattern sequence.

[7] Compilications (for SML)

(1) layered patterns of the form "x as p".
These introduce variable binding points at intermediate nodes in the pattern space.

(2) vector patterns.
These are a variant of datatype OR nodes, where the OR-descrimination is on the
length of the vector pattern. The elements of the vector form an AND node.

A position in the pattern space is determined by a node in the AND-OR tree, which
can be described by a finite path down a branch from the root of the tree.  A
path can be defined as a finite list of "links", where links can be defined by
the datatypes

    datatype link
      = R of int      (* index into a record/tuple product pattern *)
      = VE of int     (* index into the elements of a vector pattern *)
      = D of datacon  (* choice among the decendents of a datatype OR node *)
      = VL of int     (* choice among vector patterns of different lengths *)
      = C of const    (* choice among constants, where const is the sum of the
                         transparent primitive types *)
    type path = link list

The root path is the empty list of links ([]: path).

- a node in an And-Or tree corresponds to a _position_ in the pattern space.

-- a node has an associated rule set that specifies the (rule) patterns
   that are consistent with that node

- a given target value can be propagated down through an And-Or tree, following
  each consistent branch and propagating in parallel though the children of an
  AND node. When it reaches a leaf node, the resulting rule set indicates which
  rule patterns are consistent with that value.  The possible matches are formed
  by taking the intersection of the leaf node rule sets.


== [8] Terms: AND-OR trees, choices, rule sets, relevance

An AND-OR tree is a representation of the pattern space generated by a
sequence of patterns. Each node represents a merging of the
subpatterns at a given point in the pattern space from each pattern in
the sequence. The original patterns all have a common type, and each
node of the AND-OR tree has a type derived from that common types.

It is possible to _match_ a value with an AND_OR tree by "pushing" the value 
(and its subcomponents)) down the branches of the AND_OR tree in parallel. Along
some branches the value will be eliminated because it is not consistent with a
choice (i.e. a nil value will be incompatible with a cons-labeled branch.

[9] A _choice_ (or _choice point_) is a point in the pattern space (a node in the AND-OR tree)
that discrimiates based on one of the following:

(1) datatype constructors (e.g. true vs false or nil vs cons)
(2) vector length
(3) constant value (int, word, char, or string)
    
Thus we distinguish three flavors of choice point. We don't distinguish between
different types of constants, (merging them under type constCon).

At each point in the pattern space (AND-OR node), there is a set of rules that are
compatible with that node (i.e. consistent with choices made on the path from
the root to that node). These rules are said to be "live", or "active" for that point.
Only the live rules actually have a subpattern at this point (as determined by a _path_).

[10] A choice is _relevant_ to a rule (ruleno), if that rule is:

(a) live for that choice point (hasn't been eliminated by an earlier choice along the
     path to this choice point), and 
(b) is not live in some immediate child of that choice point.


This is a binary relation between choices and rules.

Being relevant to more rules is considered a positive property of a choice.
It does more discrimination.

Building a decision tree is a process of choosing an ordering of choice points.

Choice points are inherently ordered by their position along branches in the AND-OR
tree. Thus a choice below a given choice must come after the higher choice (higher
and lower being determined by position along a branch. If two choices are not on the
same branch (i.e. the path to one does not go through the other), then they are 
inherently not ordered, or are _independent.

== [11] Variables at nodes

A variable can occur at a node in one of two ways:

(1) an atomic variable node (VAR)
(2) an "as"-bound variable attached to one (or more) of a nodes patterns

Atomic, or terminal variable nodes create defaults.  All rules that are live at
that node remain live through the entire subtree determined by that node (i.e. they
cannot be excluded by a choice.

For instance, consider the pattern sequence

(1)  cons(p1,p2)
(2)  nil
(3)  x

This forms an OR node at the root:

    []: OR(list) {1,2,3} var: (x,3)
         [cons]
	    AND {1,3}  [rule 2, nil, is eliminated, but not rule 3]
	      tree(p1)
	      tree(p2)
         [nil] {2,3} *

All the rules live at the top OR-data node remain live for the two immediate
children nodes.  Note that the variable x does not consitute a child node of
the OR-data node.  But it does influence propagation of liveness -- rule 3 remains
live throughout the subtree (e.g. at [D cons] and [D nil] and in tree(p1) and tree(p2)).

Compare this with

(1)  cons(p1,p2)
(2)  nil

with AND-OR tree:

    []: OR-data {1,2}
         [D cons]
	    AND {1}
	      tree(p1)
	      tree(p2)
         [D nil] {2} *

A layered variable binding does not extend the lifetime of rules:

(1) x as cons(p1,p2)
(2) nil

    []: OR(list) {1,2}
        as-var: (x, rule 1)
         [cons]
	    AND {1}
	      tree(p1)
	      tree(p2)
         [nil] {2} *

So a primitive var pattern creates a "default" rule that remains live below
(this) node, while a layered variable does not.


== [12] From AND-OR to Decision trees

(1) determine "accessible" list of CHOICE nodes
These are the CHOICE nodes that are accessible from a root (through selection
from AND nodes) without passing through another CHOICE node.  They are located
on paths which contain no OR links.


== [13] Constructing a Decision Tree

(1) Collect the list of "accessible" OR nodes in the AND-OR tree, with accurate
live rule sets, including default rules that result from VAR/VARS nodes.
The rule of a var binding remains live in the AND-OR node containing that variable,
and thoughout the subtree below that node (i.e. its rule cannot be killed by any
choice within that subtree, including the CHOICE that is the root of that subtree.
Note that VAR nodes may be merged with an AND node _above_ the CHOICE node that 
is being evaluated.

(1)  (x,nil)
(2)  (cons(p1,p2), nil)

Here the x at (RL 1) in the first rule creates a default for the choice node 
created by cons(p1,p2), so rule 1 will be live in the choice node generated from
the cons pattern.

As-bound variables (layer variables) do not have this defaulting effect, and therefore
don't affect the selection and ordering of choice nodes during the construction of the
decistion tree (?).  AS-bindings will have to be dealt with later during the translation
of the decision tree into match code.

Once a choice node is chosen as best from the initial list (the highest set of indepenent
choice nodes), we discard that choice from the list and enqueue the accessible choice
nodes from the subtree below the chosen node (if any).  So the set of remaining choice
nodes may grow (or shrink by one if there are no choice nodes below the chosen one in
the AND-OR tree.

[14] Rule sets associated with an AND-OR node:

(1) live rules: relation Live(rule,node)
Defn. A rule is live at a node if there is no OR choice above that node that is not
compatible with that rule. This means that there exists a value that could match that
rule. If the value was pushed down the branches of the andor tree, it would not have
been eliminated by the time it reaches this node.

(2) relevant rules (static?, or relevant to choice order in a decision tree?)
Defn: Relevance (static): a node is (absolutely) relevant to a rule if that
rule is live for the node (Live(rule,node)) and the rule is not live for some
immediate child of the node (i.e. one of the choices rules it out). Can a rule
ruled out for _all_ children?  Two cases

  (a) the rule introduces one of the children of the OR nodes (in which case it
      will be live for that child.
  (b) the rule does not introduce a new child
      (b1) it contains a variant that was already introduced by an earlier rule, in
           which case it is live for that variant
      (b2) it does not introduce a variant at all, in which case it must have
           a variable at this nodes position. In this case it becomes a default
           rule for this node, and for all its descendents, and is therefore 
	   considered "live" (= live union defaults)

(3) default rules: relation Default(rule,node)
Defn: a rule is a default rule at a node if there is a variable binding for that rule
at some node on the path to the node (including the node as the end of the path).
If Default(rule,node), then that rule cannot be ruled out at that node (i.e. the
node is not relevant to that rule.

Example:

  (1) cons(x,     nil)
  (2) cons(true,  cons(y,    nil))
[ (3) cons(false, cons(true, z))  ]
  (4) _

variable x in rule 1 makes rule 1 a default for the [R1,D(cons)] node. Rule 1 is
live for that node and any descendents of that node.

  [] OR(list) cons {1,2,3; 4} (vars = (_,4)) (partial)
     [cons] AND {1,2,3}
                [0] OR(bool) {1,2,3; 1,4}  vars=(x,1)
		      [true] LEAF {2; 1,4}
		      [false] LEAF {3; 1,4}
		[1] OR(list) {1,2,3; 4}
                      [nil] LEAF {1; 4}
		      [cons] AND {2,3; 4}
 		                 [0] OR(bool) {2,3; 2,4} (vars = (y,2)) (partial)
				       [true] # {3; 2,4}
				 [1] OR(list) {2,3; 4} (vars = (z,3) (partial)
				       [nil] {2; 34}

A _partial_ OR node is a datatype or node with not all datacons represented
in the children of the node.  

(All constant (except char) and vector OR nodes are partial by default.)

live(node) = {rule: Live(rule,node)}

live [] = allrules



================================================================================
[15] Theory: pattern space, paths, types
================================================================================

Defn. A patternable type is a type with some concrete product and sum (datatype)
structure at the top (where ty vector is an "honorary datatype descriminating on
the vector lenght).  Some primitive types (int, word, char, string) are also
deemed patternable.  Abstract types and function types are not patternable.

Defn. Abstractly, a tree is a prefix-closed set of paths (Milner, Webs, 1985). Each
path determines a "node" in the tree, and nodes can have attributes attached to them.
"Paths" are lists (finite or infinite) of "links", which may have structure and
attributes of their own.

Defn. Path concatention. If p and p' are paths, p@p' is the concatenation of the
paths, consisting of the links of p followed by the links of p' (the concatenation
of the paths as lists of links).

Defn. A path p' is a _prefix_ of a path p if E(p''). p = p'@p''. (depends on an
equality relation on links)

Defn. If T is a tree, T' \subset T is the _subtree_ at path p if T' consists of all paths
in T having p as an prefix.  Subtree(p,T) = {p' | p@p' \in T).  It is a tree (prefix closed).

Defn. An _initial_ tree of a tree T is a prefix-closed subset of T. A finite initial tree
is an initial tree that is finite.

For any patternable (ML) type t, there is a pattern tree P(t) that expresses the potential
pattern spaces of the type.  This tree has nodes of three kinds:

 (1) product (AND) nodes that may have a finite number of successors (or children)
     indexed by natural numbers (non-negative integers). The subtype at a product
     node is a product (record, tuple) type.

 (2) sum (OR) nodes, that have a finite number of successors indexed by "keys" that
     are either data constructors (datacons) for a datatype, or constants
     (for a patternable primitive type). The subtype at a sum node is a sum type
     (i.e. a datatype).
 (3) terminal (LEAF) nodes for constants (datatype or primitive)

Note: Vector types are treated as a kind of sum type (over some finite
range of vector lengths).  Natural numbers serve as keys for vector
types, indicating to the vector length.

Let t be a patternable type. A pattern pat: t is represented as an initial
tree of P(t).

Defn: Pat(p) \subset P(t) where pat: t.
(inductive definition on pattern structure or concrete structure of type t)

A variable in a pattern generates a (potentially infinite) subtree of the P(t).

Defn. The pattern space of a pattern list is the union of Pat(pi) for pi \in pat list.

This pattern space is represented concretely by an AND-OR tree.


================================================================================
[16] Variable patterns, live rulesets, default rulesets, propagation of defaults
================================================================================

Notational conventions for links, paths, keys:
  [n] represents [Rn], where n is the index of a product/tuple/record component (0 based)
  [K] represents [D(K,_)] where K is a dataconstructor name
  (not currently using other constant keys (num, char, string) in examples)

Conjectures:
1. live field of AND nodes do not play a role.  But live sets during decision tree
   building need to be propagated down through AND nodes.
2. Same for live field of VARS nodes?

[datatype t = A | B | C]
  (0) A
  (1) x
  (2) C

N0:
[] OR(t) {0,1,2}  Vars (x,2)
   [A] {0; 1x}
   [C] {2; 1x}

Rule 2 is default for the [A] and [C] variants.

Some rules may become "inaccessible" because of defaulting from variables.
In this example, rule (3) will never be "fired" in a match because it is
"shadowed" by rule (2).

Thus rule (3) will never be chosen on a branch of the decision tree (because,
while it may be live at a leaf, it will not be the _least_ live node at a leaf.
Here we have

  [] DEC(t)
     A {1,2x}  -- 1 chosen
     C {2x,3}  -- 2 chosen
     [B] {2x}  -- default branch

C leads to live set {2,3} which will select the least rule, i.e. (2).
B goes down an "else" branch with default ruleset {2}
A leads to live set {1,2} which selects rule (1)
Rule 3 is redundant, will never be matched.

r in Defaults(Node)
  ==>
  (1) Var(Pat(r)[Path(Node)]), or
  (2) Exists p < Path(Node). Var(Pat(r)[p])

which is the same as:

   Exists p <= Path(Node). Var(Pat(r)[p])

This means that Pat(r)[p] _cannot cause a mismatch_.

If for p0 < Path(Node), Var(Pat(r)[p]). r contributes no
pattern structure below p0. There may be pattern structure below
p, but it is contributed by other rules (earlier or later than r).

In above example: Var(Pat(2)[[]])


Defn: Relevant(N,r): An OR node N is relevant to a rule r if
  the choice made at that rule can affect whether that rule matches
  i.e. some variant is compatible with that rule and another variant
  is incompatible with that rule.
  i.e. Pat(r)[Path(N)] is not a variable, therefore is either
       a constant or a constructor (constant or applied)
       therefore Pat(r)[Path(N)] is a key for the choice made
       at N (N.variants).

Defn: Pat(r) (r a ruleno) is the pattern part of rule r (r.pat)

Defn: Pat(r)[p] = pattern element at longest possible prefix of
      path p in Pat(r).

Prop: Var(Pat(r)[N]) <=> r in Defaults(N)

Defn: Given an andor tree N for a given rule set
    Compat(r,p) if Pat(r) is "compatible" with all choices made
    on path p.

Notation: N an andor tree, p a path, Np is the andor tree found at
  the end of path p.
    N[] = N
    N[CL(c)] = LEAF ...
    N[DL(d)] = N' where N = OR{variants=ORdata [(d,N'),...],...}
    N[VL(l)] = N' where N = OR{variants=ORvec [(d,N'),...],...}
    N[RL(i)] = Ni where N = AND [..., Ni,...]
    otherwise, N

Defn: Compat(pattern, andor) : 
      Compat(pat, N[])  -- no choices made (yet) at root path
      Compat(c, N[CL(c)])   -- constant pattern; N is OR[ORconst] = LEAF
      Compat((p0,p1), AND(a0,a1)) if Compat(p0,a0) and Compat(p1,a1)
        -- and so on for n-ary products  (a0 = N[RL(0)], a1 = N[RL(1)]
      Compat(d, N[DL(d)])   -- constant datacon
      Compat(d(p), N[DL(d)]) if Compat(p,N)
      Compat(v, N))  true
   In which case r is live for node N(p)

pat@path = the subpattern (if any) of pat at the point designated
           by path (if "compatible")

Prop: Compat(r,p) <==> r in Live(Node(p)) ?

Prop: If Var(Pat(r)[path]), then r in Defaults(N(path)),
      where N = andor(rules).

Note: Pat(r)[path] is always defined, though the actual path for this
subpattern may be a strict prefix of path.


================================================================================
[17] Worked Examples
================================================================================

[18] Example 1:

datatype tree = L | N of tree * tree

      [0]         [N]
              [N0]  [N1]
  (0) N      (x,    L)
  (1) N      (L,    y)
  (2) z

AND-OR tree:
([n] is short for [Rn] (record selection n))

[] OR(tree) {0,1,2z}
   [N] AND {0,1,2z}
       [0] OR(tree) {0x,1,2z}
           [N] # {0x,2z}
	   [L] LF {0x,1,2z}
       [1] OR(tree) {0,1y,2z}
           [N] # {1y,2z}
	   [L] LF {0,1y,2z}
   [L] LF {2z}

Priorities:
  []   : (1,2)
  [N0] : (2,2)
  [N1] : (2,2)
  
  [] < [N0] = [N1]
  [N0] || [N1]  ([N0] and [N1] are compatible; diverge at AND node [N])
  [N0], [N1] dominated by [] ([] is a prefix of ...)

Decision Tree:

D[] {0,1,2(z)}
   N : {0,1,2z}
       Relevance:
         [N0] false (0 \in {0x,3z})
         [N1] true  (0 not \in {1y,2z})
     D[N1] {0x,1,2z}
        N*: {1y,2z}   ==> (1)
	    Relevance:
	      [N0] false (? not in {0x,2z}) [no _hard_ live rule]
	L : {0,1y,2z} ==> (0)
	    Relevance:
	      [N0] (0 in {0x,2z}) false
   L*: {2z} ==> (2)	       
       Relevance:  [N0], [N1] not compatible with [L] (diverge at OR[0])

Abbreviated Decision Tree:

  []
  N =>
    [N1]
    N* => (1)
    L => (0)
  L* => (2)

Note: OR node [N0] not used, because not relevant after [N1].

Code:

   Case vtop                 (vtop = v[0]: tree)
     of N v1 =>              (v1 = v[N]: tree * tree)
          letr (v2,v3) = v1  (v2 = v[N0]: tree, v3 = v[N1]: tree)
            in Case v3
	         of N => RHS 1
	          | L => RHS 0
        L => RHS 2

Code with external variable bindings:

   Case vtop                 (vtop = v[0]: tree)
     of N v1 =>              (v1 = v[N]: tree * tree)
          letr (v2,v3) = v1  (v2 = v[N0]: tree, v3 = v[N1]: tree)
            in Case v3
	         of N =>
		    Let1 y = v3 in RHS 1
	          | L => Let1 x = v2 in RHS 0
        L => Let1 z = vtop in RHS 2

================================================================================
[19] Example 2:

       [0]     [1]     [2]
 
  (0)  true,   false,  true
  (1)  true,   x,      false
  (2)  false,  true,   y

AND-OR tree:

[] AND
   [0] OR(bool) {0,1,2}
         [true]  LF {0,1}
         [false] LF {2}
   [1] OR(bool) {0,2; 3y}  var: (x,2)   [2 goes to defaults, not live]
         [true]  LF {2; 1x}
         [false] LF {0; 1x}
   [2] OR(bool) {0,1; 2y}  var: (y,3)
         [true]  LF {0; 2y}
         [false] LF {1; 2y}
   
Priorities:
   [0] : (0, 2)   (#defaults, width)
   [1] : (1, 2)   (#defaults, width)  (x, 2)
   [2] : (1, 2)   (#defaults, width)  (y, 3)

   [0] < [1] = [2]

Relevance: {1,2,3}, least: 1
   [0]: true  (1 /in {})
   [1]: true  (1 /in {2x})
   [2]: true  (1 /in {3y})

Decision tree:

D[0] {1,2,3}
   true  : {1,2}, least: 1
      Relevance: [1]: true  (1 not in defaults = {2})
                 [2]: true  (1 not in defaults = {3})
      D[1]  {1,3; 2x}
         true  : {2x,3} inter {1,2} = {2}, least: 2
	   Relevance: [2] : true  (2 not in defaults = {3}); [1],[2] compatible
	   D[2] {1,2,3y} > {1,3!}
	      true  : {1,3!} inter {2} = empty ==> MATCH!
	      false : {2,3!}, least: 2   
	        no more choices  ==> (2)
	 false : {1,2x} inter {1,2} = {1,2}, least: 1
	   Relevance: [2] : true  (1 not in defaults = {3}); [1],[2] compatible
	   D[2] {1,2,3y}
	      true  : {1,3!} inter {1,2!} = {1}, least : 1  ==> (1)
	        [[no more choices  ==> (1)]]
	      false  : {2,3!} inter {1,2} = {2}, least : 1  ==> (2)
	        [[no more choices  ==> (2)]]
   false : {3}
      Relevance: [1] : true  (3 not in defaults={2})
                 [2] : true  (3 not in defaults={2})
      D[1] {1,3; 2}
         true: {2!,3} inter {3} = {3}, least: 3  ==> (3)
	   [[ Relevance: [3]: false  (2 in defaults = {2})   [==> (3)] ]]
	 false: {1,2!} inter {3} = {},    ==> MATCH!
	   [[ Relevance: [3]: true  (1 not in defaults = {3})
	   D[2]: {1,2; 3}
	      true: {1,3!}, least: 1
	        no more choice nodes  ==> (1)
	      false: {2,3!}, least 2
	        no more choice nodes  ==> (2)  ]]

Abbreviated decision tree:

  [0]
  true =>
    [1]
    true  => 
      [2]
      true  => MATCH!   (counterexample: (true,true,true))
      false => (2)
    false =>
      [2]
      true  => (1)
      false => (2)
  false =>
    [1]
    true  => (3)
    false => MATCH!   (counterexample: (false,false,*))

Tests: (true,true,true) ==>  MATCH!
       (false,true,false) ==> (3)
       (false,false,false) ==> MATCH!

Code:
  Letr (v1,v2,v3) = root (argument/scrutinee)
    in Case v1
         of true =>
	     Case v2
	       of true  => 
		   Case0 v3
                      of true  => Raise Match
		       | false => RHS 2
		| false =>
                   Case0 v3
		      of true  => RHS 1
		       | false => RHS 2
          | false =>
	     Case v2
               of true  => RHS 3
	        | false => Raise Mmatch
		 

================================================================================
[20] Example 3:
(where a rule is chosen because no relevant OR nodes)

Type:    t * bool *  bool
        [0]  [1]     [2]
-----------------------------
  (0)  (A,   false,  true)
  (1)  (B,   x,      false)
  (2)  (z,   true,   y)

AND-OR tree

[] AND
   [0] OR(t) {0,1,2z}  -- [partial]
         [A] LF {0,2z}
         [B] LF {1,2z}
   [1] OR(bool) {0,1x,2}  var: 1x
         [true]  LF {1x,2}
         [false] LF {1,1x}
   [2] OR(bool) {0,1,2y}  var: 2y
         [true]  LF {0,2y}
         [false] LF {1,2y}
  
Priorities:
  [0] : (1,2)
  [1] : (1,2)
  [2] : (1,2)
(all three nodes have 1 variable, 2 keys ==> equal priorities)

top accessible = [[0],[1],[2]]

D[0] {0,1,2}  (= allrules)
   A  : {0,2z}, least: 0
      Relevance:
        [1]: true  (0 not in defaults = {1x}) -- chosen
        [2]: true  (0 not in defaults = {2y})
      D[1] {0,2}
         true  : {1x,2} inter {0,2} = {2}, least: 2  ==> (2)
	       Relevance:
	         [2]:  (2 in {2y}) false
	 false : {0,1x} inter {0,2z} = {0}, least: 0
	   Relevance: [2] : true  (0 not in defaults = {2y})
	   D[2] {0}
	      true  : {0,2y} inter {0} = {0}, least : 0  ==> (0)
	        [no more OR nodes  ==> (0)]
	      false : {1,2y} inter {0} = {}  ==> MATCH (A,false,false)
	        [no more choices -- irrelevant]
   B : survivors = {1,2z}, least: 1
      Relevance:
        [1] : false  (1 is in defaults[1]={1x})
        [2] : true  (1 not in defaults[2]={2y})
      D[2] {1,2z}
         true: {0,2y} inter {1,2z} = {2yz}
	   Relevance:
	     [1]: (2 not in {1x}?) true
	   D[1] {0,2y}
	      true  : survivors = {1,2z} inter {0,2y} = {2zy}
	         OR-nodes exhausted ==> (2)
	      false : survivors = {0,1x} inter {2} = {}  ==> MATCH
	 false: {1,2y} inter {1,2z} = {1,2yz}, least {1},  ==> (1)
	   Relevance: [1]: false  (1 in defaults = {1x})
	   no relevant OR node => choose least({1,2yz}) = (1)
   * : {2z} [not finished: e.g. (C,false,*) doesn't match]
      Relevance: [1] : (2 not in {1x}) true
                 [2] : (2 in 2y} false
      D[1] {2}
         true: {1x,2} inter {2} = {2}
           D[2] not relevant ==> (2)
	 false: {0,1x} inter {2} = {}  ==> MATCH (C,false, any)
	 
Abbreviated decision tree: (exhaustive)

  [0]
  A =>
    [1]
    true  => (2)
    false =>
      [2]
      true  => (0)
      false => MATCH  (A,false,false)
  B =>
    [2]
     true  => (2)
       [1]
       true => (2)
       false => MATCH  (B,false,true)
     false => (1)
  * =>  [C]
    [1]
     true => (2)
     false => MATCH  (C,false, *) 


=========================================================================================
[21] Example 4:
(where rule is chosen because no relevant OR nodes)

  (0)  A,  false, true
  (1)  B,  x,     false
  (2)  z,  true,  false

AND-OR tree

[] AND
   [0] OR(t) {0,1,2z}     var: 2z
           [A] LF {0,2z}
           [B] LF {1,2z}  (only _explicit_ keys appear in andor tree)
   [1] OR(bool) {0,1x,2}  var: 1x   [1 goes to defaults, not live]
           [true] LF {1x,2}
           [false] LF {0,1x}
   [2] OR(bool)] {0,1,2}
           [true] LF {0}
           [false] LF {1,2}

*** andor ***
[] AND {0,1,2} {}
   [0] OR {0,1} {2}  (vars: (z,3))
      A LEAF {0} {2}  {0,2z}
      B LEAF {1} {2}  {1,2z}
   [1] OR {0,2} {1}
      T LEAF {2} {1}  {1x,2}
      F LEAF {0} {1}  {0,1x}
   [2] OR {0,1,2} {}
      T LEAF {0} {}   {0}
      F LEAF {1,2} {} {1,2}

Priority:
  [0] : (1,3)  (2 variants + default = 3 branches)
  [1] : (1,2)  (2 variants, 2 constructors *)
  [2] : (0,2)

  [2] > [1] =? [0]

top accessible = [[0],[1],[2]]
all three OR nodes compatible: [0] || [1], [0] || [2], [1] || [2]
  (diverge from []AND )

Decision Tree:

D[2](bool) {1,2,3}  (= allrules)
  true : survivors' = {0}, least: 0
      Relevance:
        [0]: true  (0 not in {2z})
        [1]: true  (0 not in {1x})
        priority [1] > priority [0]
      D[1](bool) {0,1x,2}
        true : survivors' = {1x,2} inter {0} = {}  ==> MATCH 
	false: survivors' = {0,1x} inter {0} = {0}, least: 0
	   Relevance: [0]: (0 not in {1x}?) true
	   D[0] {0,1,2z}
	     A: survivors' = {0,2z} inter {0} = {0}  ==> (0) (no more OR nodes)
	     B: survivors' = {1,2z} inter {0} = {}  ==> MATCH
	     *: {2z} inter {0} = {}  ==> MATCH  <--- failure!!!  Catch this and generate MATCH
  false: survivors = {1,2}, least 1
      Relevance:
        [1]: (1 not in {1x}?) false,
        [0]: (1 not in {2z}?) true
           [1] not relevant, so [0] chosen, even though lower priority
      D[0](t) {0,1,2z}
        A: survivors' = {0,2z} inter {1,2} = {2}, least: 2
	   Relevance: [1] (2 not in {1x}?) true
	   D[1]: {0,1x,2}
	     true: survivors' = {1x,2} inter {2} = {2}
	       queue exhausted  ==> (2)
	     false: survivors' = {0,1x} inter {2} = {} ==> MATCH
        B: survivors = {1,2z} inter {1,2} = {1,2}; least 1
	   Relevance:
	     [1]: (1 not in {1x}? => false)
	     no more relevant tests  ==> (1) least of {1,2}
	*: survivors = {2z} inter {1,2} = {2z}
	   Relevance:
	     [1]: (2 not in {1x}?) true  (2 least live, even though from defaults)
	   D[1]: {0.1x.2}
	     true: survivors = {1x,2} inter {2z} = {2}  ==> (2) (OR node queue exhausted)
	     false: survivors = {0,1x} inter {2z} = {}  ==> MATCH
	     
Abbreviated decision tree:

  [2]
  true =>
    [1]
    true  => MATCH     (*,true,true)
    false =>
      [0]
      A  => (0)
      B  => MATCH      (B,false,true)
      * => MATCH       (C,false,true)
  false =>
     [0]
     A => 
       [1]
       true => (2)
       false => MATCH  (A,false,false)
     B => (1)
     * =>
       [1]
       true => (2)
       false => MATCH  (C,false,false)
  
Code:

  Letr (v1,v2,v3) = root
    Case v3
      true =>
        Case v2
	  true => MATCH
	  false =>
	    Case v1
	      A => RHS 2
	      B => MATCH
	      * => MATCH
     false =>
       case v1
         A =>
	   Case v2
	     true => RHS 2
	     false => MATCH
	 B => RHS 1
	 * =>
	   Case v2
	     true => RHS 2
	     false => MATCH
		

================================================================================
[22] Theory (Clarification): live ruleset, defaults ruleset, relevance, survival
================================================================================

(re: Construction of decision tree)

Rule sets are associated with andor nodes, which represent/designate points in the
pattern space (through their path).

Let's say the "live" ruleset is the set of all rules that have a chance of
  successfully matching at a given pattern point.

Live rules can be characterized as either "direct" or "default".

A rule is a "direct" live rule at p if that rule/p determines/contributes/matches
a particular discriminator key (constructor or constant or vector length). Thus

in the example 

       [p] OR(bool)
   (0) true   ...
   (1) x      ...
   (2) false  ...

rules (0) and (2) are directly live at [].  Rule (1) introduces a variable
default (1x), which also matches the direct keys true and false.  So for
this node:

  direct = {0,2}
  default = {1}

The live ruleset is

  live = direct U default = {0,1,2},

sometimes writen as {0,1x,2} to make it clear that 0 and 2 are direct and
2 is a default (introduced by the occurrence of x).

CONJECTURE: The relevance test should use the least rule in the _live_ set,
which includes both direct and default rules. This least rule may therefore
be a default rule.

Thus at a point in the decision tree construction, rule (0) may have been
eliminate by a higher ([]) false choice (in another column), in which case
the surviving live rules may be {1,2}.  A futher decision may be able to
elimate (1) even though 1 \in defaults.

At an OR node, there is a set of _live_ rules.  Each associated key for that
node determines a subset of live, live/key that is consistent with that key.
These are the rules that have that key at this pattern point, or are default
rules (because of having a variable at that pattern point or above on the path).

In the decision tree construction, the effective live set (for a given key)
is the intersection of live/key and the surviver set being passed down from
higher in the decision tree, i.e.

  survivors' = survivors inter (live/key)

This is the ruleset that should be passed to the call of makeDecisionTree
to compute that decVariant (key,dectree).  It eliminates direct rules with
keys other than the current key. E.g. in the above example, for key false,
live = {0,1x,2} and live/false = {1x,2} and if survivors = {0,2}, say, then
the new survivors for the call of makeDecisionTree for this decVariant is

  survivors' = {0,2} inter {1x,2} = {2}

CONJECTURE. direct and defaults rulesets are only active for OR nodes, so
they don't need to be computed or saved for other kinds of nodes: AND, SINGLE,
VARS, LEAF.

For an OR node, each ruleno in direct is associated with some key in
the variants. If we want to isolate the rulenos introduced with some
particular key, how can we do that?  Look at the andor in that key's
variant, use its direct ruleset. This will be a subset of the OR nodes
direct (?). But its andor may be an AND or a LEAF, or a SINGLE. So have
to be able to derive their direct and defaults sets. Thus any andor that
can be the andor of a variant will have to have direct and defaults.


================================================================================
[23] OR node queue management in DecisionTree
================================================================================
File: dec-tree.sml

OR nodes get "used up" while building a branch downward.
They do not get "used up" across separate, incompatible branches.

Hence, a node is passed down and as decision nodes are added, the queue
is eventually exhausted, _or_ the decision tree branches may terminate
while the queue is still not empty (redundant OR nodes).

Under each variant of an OR node, new (dominated) OR nodes may become
accessible, but OR nodes from "sibling" variants will be incompatible
and do not need to be added to the queue. Only OR nodes within that
variant andor need to be added for further consideration.

Defn: Two andor nodes or paths are compatible if the point where they first
diverge is not a choice key (i.e. is an R key).

Defn: An OR-node queue is (internally) compatible if any pair of nodes
in the queue are compatible.

Prop: If two nodes are incompatible, they cannot both be tested in a single
(dynamic) match.

Important invariants:

1. The OR node queue returned by the accessible function in OrderedOrNodes
will always be compatible, because all paths will differ at AND nodes --
OR-nodes terminate the traversal and their variants are not explored.

2. In makeDecsionTree (DecisionTree) The variantCandidates queue will be
compatible if the candidates queue returned by selectBestRelevant is
consistent, because all new OR nodes added lie beneath a single key variant
of the OR node chosen (from orNodes argument).
2.1. The top call of makeDecisionTree will be passed (as orNodes) the queue
produced by accessible applied to the top andor node.
2.2. Hence (inductively) all calls of makeDecsionTree will be passed compatible
queues.
2.3. selectBestRelevant will be passed a compatible queue, and the path
argument will be either (1) rootPath (for top call) or (2) the path of one of
the earlier, previously selected, compatible queues, and hence the path will
be compatible with all the nodes in the queue argument.  Hence the compatibility
test in the filter used in selectBestRelevant is redundant. (Check by
generating a warning message, or impossible message.)

================================================================================
[24] OR node priorities
================================================================================
The priority function is based on two factors:

  (1) number of default rules (fewer is better)
  (2) branching factor

At a first approximation, branching factor = number of variants
(length(variants)). But if there is a default rule (covered by a
variable) that can apply where there are missing constructors (keys),
then the branching factor can be

   length (variants) + 1  (for the default branch)

Does this occur only where variants are _partial_, meaning some keys
(e.g. datacons) are missing? [See example 4, path [0]].  Or is it
possible that a default with a _complete_ list of variants (covering
all constructors) can result in an increased branching factor?

Example (conjectural)

      p
  (0) T
  (1) F
  (2) x

Could the x in rule (2) result in a third branch at position p?

================================================================================
[25] Code generation
================================================================================
File: mc-code.sml

Provisional datatype for code: mcexp

Variables:
_Internal variables_ used to name value components. These are in 1-1 correspondence
with paths in the pattern space of the match (and hence AND-OR nodes). Could
generate a fresh internal variable as we construct each andor node, and then
would have the variables already available and "connected" with their path.

Otherwise, might maintain a mapping or two:

  variable --> path == node
  path/node --> variable

Multiple _external_ variables (the source variables that appear in the patterns)
may be associated (equivalent, denote the same value component) with a given
internal variable.  (i_variable <--> node => vars, asvars).  Will need parallel
bindings of internal and external variables (or bindings on external variables
_to_ internal variables).

Each internal variable will have a definite type == the type of the node/path,
== the type of corresponding value components.  Some of these types will be
represented by type variables (not metavariables/univariables!).
Make the abstraction over these "real" type variables explicit.

  AND(v0, [N1(v1), N2(v2), ..., Nn(vn)\])  ==>
   
    letr (v1,v2,...,vn) = v0  (* destructuring a product value *)
      (unpackaging(next choice))
       
  OR(v0, [(k1,N1(v1)), (k2,N2(v2)), ..., (kn,(Nn(vn)))])  ==>

    case v0          (v0 is the "scrutinee" *)
      k1 v1 => exp1  (= (unpackaging(next choice)))
      k2 v2 => exp2
      ...
      kn vn => expn

  For some keys, there will not be arguments, hence no variable binding needed.
  vi designates the ki-destructuring of the value bound to v0, etc.

  Example:

      (1) nil => rhs1
      (2) cons(x,y) => rhs2

      OR v0
        [(nil, LEAF({1})),
	 (cons, AND(v1, [VARS(v2,[(x,2)],{2}), VARS(v3,[(y,2)],{2})]))]

      case v0
        nil => rhs1
	cons v1 =>
	  letr (v2,v3) = v1
	    rhs2'     -- need to identify x with v2 and y with v3
	              -- or substitute (v2,v3) for (x,y) in rhs2

Observations
* Each OR node scrutinizes a particular point in the value structure
  (determined by its path in the pattern space), assuming the value
  is compatible with that path (agrees with OR choices along the path).

* Each value (component) scrutinized should be named by a (internal) variable.
  - A variable could be assigned to every AND-OR node, even though not all such
  variables might be needed -- but most of them will be used.  We don't need
  internal variables for LEAF nodes, since their partent OR node will have a
  variable naming the value already.
  - Some "internal" variables will pair with "external" variables (from vars
  or asvars fields).  How do we manage this association?
  

Example 3: [ datatype t = Leaf | Node of t * t ]

      Node   1               2      Node  1                  2
  (0) Node  (Leaf,           Node        (Leaf,              x))
  (1) Node  (Node(y, Leaf),  Node        (Node(Leaf, Leaf),  Leaf))
  (2) Node  (z,              Leaf)
  (3) Leaf

Andor:

1 [] OR(t) {1,2,3,4}
    [Node] AND {1,2,3}
2      [1] OR(t) {1,2,3z}     (var: (z,3))
            [Node] AND {2,3z}
4	      [1] OR(t) {2y,3z}  (var: (y,2))
5	      [2] OR(t) {2,3z}
	          [Node] - {3z}
	          [Leaf] # {2,3z}
	    [Leaf] # {1,3z}
3      [2] OR(t) {1,2,3}
            [Node] AND {1,2}
6	      [1] OR(t) {1,2}
	           [Node] AND {2}
8	             [1] OR(t) {2}
		          [Node] - {}
	                  [Leaf] # {2}
9		     [2] OR(t) {2}
		          [Node] - {}
	                  [Leaf] # {2}
                   [Leaf] # {1}
7	      [2] OR(t) {1x,2}  (var: (x,1))
	           [Node] - {1x}
	           [Leaf] # {1x,2}
	    [Leaf] # {3}
    [Leaf] # {4}

Priorities:
1 []                     = (0,2)
2 [Node,1]               = (1,2)   (z)
3 [Node,2]               = (0,2)
4 [Node,1,Node,1]        = (2,2)   (y,z)
5 [Node,1,Node,2]        = (1,2)
6 [Node,2,Node,1]        = (0,2)
7 [Node,2,Node,2]        = (1,2)   (x)
8 [Node,2,Node,1,Node,1] = (0,2)
9 [Node,2,Node,1,Node,2] = (0,2)

Decision tree:

  D[[]] {1,2,3,4}
    Node: {1,2,3}, least 1
       Relevance: [Node,1] true, (1 not in {3z})
       Relevance: [Node,2] true, (1 not in {})
       [Node,2] {1,2,3}  ("lower" priority)
         Node: {1,2} inter {1,2,3} = {1,2}
	 Leaf: {3} inter {1,2,3} = {3}
    Leaf: {4}, least 4  (do we need more choices in this case?)
       Relevance: [Node,1] true, (4 not in {3z}); Compatible: false
       Relevance: [Node,2] true, (4 not in {});   Compatible: false

* Only use "path compatible" tests.
  E.g. [Node,1] is not "compatible" with the decision branch [Leaf].
  so it should not be tested under Leaf.

* When choosing the next OR node in building a decTree, the set of
  OR nodes selected from should be "independent of"(?) and "consistent
  with" the current branch/node in the decTree that is being extended.

* Two nodes are consistent if their paths have no divergences.  A divergence
  is a point on the two paths where distinct and inconsistent keys are followed
  to the next node.  E.g. [... D(true) ...] and [... D(false) ...] where the
  true and false keys occur at the same point (the ith link) in the path.

* Being consistent means that both nodes can be "fired" during the matching
  of some potential value.

* In Example 3 above, the [Leaf] path is inconsistent with all the remaining
  OR nodes, since they all have paths beginning with [Node ...]. The first
  links (keys) in the paths are inconsistent. Therefore the [LEAF] node of
  the decTree is terminal -- there will be no further tests on this branch.
  
* Defn: Two paths p1 and p2 are incompatible ("diverge hard") if the first
  link (key) at which they differ is an OR (choice) key, e.g. D(true) vs
  D(false) or I(1) vs I(2).  Two OR nodes N1 and N2 are _incompatible_ if
  their paths Path(N1) and Path(N2) are incompatible.

  Prop: If OR nodes N1 and N2 are incompatible, then they will not both be
    tested when matching a value.  In particular, they will not be comparable
    in the path prefix ordering.  There is a test that dominates both N1 and
    N2 that discriminates between them, namely the test that is the source of
    the two divergent keys on their path.

  When selecting the next OR node while building the decision tree, the
  selected node should be both _relevant_ and _compatible_ with the "current"
  node.

Decision Tree 1 (8 ORs)

   []
   Node =>
      [N2]
      Node =>
         [N2N1]
         Node =>
            [N2N1N1]
            Node => MATCH!
            Leaf =>
               [N2N1N2]
               Node => MATCH!
               Leaf =>
 	          [N1]
                  Node =>
                     [N2N2]
	             Node => MATCH!
	             Leaf => (2)
                  Leaf => MATCH!
         Leaf => 
            [N1]
            Node => MATCH!
            Leaf => (1)
      Leaf => (3)
   Leaf => (4)
  
Decision Tree 2 (hand crafted) (8 ORs)

   [] 
   Node => {0,1,2}
      [N2]
      Node => {0,1}
         [N2N1]
         Node => {1}
            [N2N1N1]
	    Node => {} MATCH!
	    Leaf => {1}
	       [N2N1N2]
	       Node => {} MATCH!
	       Leaf => {1}
	          [N1]
		  Node => {1}
		     [N1N2]
		     Node => {} MATCH!
		     Leaf => {1} (1)
		  Leaf => MATCH!
         Leaf =>
            [N1]
	    Node => {} MATCH!
	    Leaf => {0} (0)
      Leaf => (2)
   Leaf => (3)

Code:
(No context around top decision node.)

  Case root  (* [] *)
    of Node v1 =>
         letr (v2,v3) = v1   (* v2 = Var[N1], v3 = Var[N2] *)
	   in Case v3  -- [N2]
	        of Node v4 =>
		     Letr (v5,v6) = v4
		       in Case v5  -- [N2N1]
		            of Node v7 =>
			         Letr (v8, v9) = v7
			     | Leaf =>
			         Case v2 ...
		 | Leaf => RHS 3
     | Leaf => RHS 4

--------------------------------------------------------------------------------
Example: mctest/t6.sml

fun f (x::y, z) = x > 0
  | f (nil, x) = not x;

andor:
[] AND v8 {0,1} {}
   [0] OR v9 {0,1} {}
      :: [0,::] AND v10 {0} {}
         [0,::,0] VARS v11 (x,0) {0}
         [0,::,1] VARS v12 (y,0) {0}
      nil LEAF {1} {}
   [1] VARS v13 (z,0) (x,1) {0,1}

dectree:
DEC [<0>]
  ::  DLEAF 0
  nil DLEAF 1

code: (for match only)

  letr (v9,v13) = v8  (= arg f)   ( v9 = x::y | nil ;  v13 = z | x )
    switch v9
       of :: v10 =>               ( v10 = (x,y) )
          letr (v11, v12) = v10   ( v11 = x_0; v12 = y_0; :: destruction )
	    v11 > 0               ( [v11/x_0] (x > 0) )
        | nil => not v13          ( [v13/x_1] (not x) )

For function f:

FN (v8) =>
  letr (v9,v13) = v8 (= arg f)     ( v9 = x::y | nil ;  v13 = z | x )
    switch v9
      of  :: v10 =>                ( v3 = (x,y) )
          letr (v11, v12) = v10    ( v4 = x(0); v5 = y(0) )
	    v11 > 0                ( [v4/x(0)] (x > 0) )
       |  nil => not v13           ( [v2/x(1)] (not x) )

Actual (buggy):

let v9 = #0 v8
  let v13 = #1 v8     (* no switch on v9: int list *)
    Int.> (v11,0)     (* no binding for v11 !!! *)

letr (v9, v13) = v8   (* top AND destruction *)
    v11 > 0           (* no switch, no binding for v11 !!! *)

FIX: return inner for VAR case of genTop in genNode in mc-code.sml.

--------------------------------------------------------------------------------
Example: mctest/t7.sml

fun f(x::y) = x;


================================================================================
[26] Adding types, polymorphism, type variable bindings
================================================================================

Observations:

1. The type of all the rules is known (post type checking).

2. The type of any andor node (path, point in the pattern space) can easily
be computed.

3. Be careful to distinguish between _real_ type variables and type
_metavariables_ (or unification variables), which are part of the type
inference machinery, but shouldn't appear in the types per se.
Definition of type needs to be modified to include _real_ type variables.

4. Real tyvars should have well-defined, explicit binding points.
Need a new Absyn construct for binding _real_ type variables.

Example: null

  fun null Nil => true
    | null (Cons(x,y)) => false
    
LHS pats
  (0) Nil           ConPat(Nil,tvs)  where tvs : tyvar list (produced by TC)
  (1) Cons(x,y)

[Typed] Code:

  let null = 
      TFN X =>   (* X is a real tyvar *)
        fn (x: X list) =>
	   Case[X list] x
	     Nil => true[bool]
             Cons v => false[bool]   [v : X * X list, not used]

  null : (All X) X list -> bool

Where do we get X?  From an (uninstantiated) tyvar extracted from where?
From the pattern(s) type or from tvs stored with datacons (which are lists
of type metavariables).

tvs : tyvar list left by TC, which may be instantiated, in which case
their instantiations may contain further uninstantiated ty metavariables
which should be abstracted.

The pattern type could either be stored by the type checker in the
"rule" datastructure, or reconstructed from the basic "constructor"
values in the patterns (or just first pattern?) and the instantiation
information in the tvs fields for datacons and the element type for
vector patterns.  Uninstantiated metavariables in the pattern type
could then be instantiated to new "real" tyvars, which could be abstracted
over by a new TFN form in Absyn.

-------
Probably best to add types to the variables as they are created during
makeAndor.  The top type would be passed to makeAndor along with the patterns.
It would be broken down into appropriate components as the function recurses
over pattern structure (which is coordinated with the type structure anyway).
The top type should have "generalized" type variables instantiated to real
tyvars, but it may contain tyvars generalized in an outer scope, so the list
of tyvars generalized "at" this match should be available explicitly, and
the match code would be wrapped in a TFN binding of these "locally" generalized
tyvars.  The type passed to makeAndor should be compressed and free of
meta-tyvars, which makes it simpler to break down (no pruning needed).

The type checker needs to be modified to:

(1) intantiate the generalized meta-tyvars to fresh _real_ tyvars, and

(2) add these abstracted/generalized tyvars to the abstract syntax in
some appropriate way (perhaps as a temporary kludge, there might be a
tyvar list ref element included in the appropriate construct (match, fn, binding, ?).
When type checker is modified to produce a new "typed" abstract syntax, the
representation could be more direct in terms of an appropriatley scoped binding
construct like TFN.

The inferred+generalized type of the lhs of the rules (i.e. the patterns) should
also be available in the absyn in order to be passed to makeAndor with the
patterns. [It could be reconstructed by effectively re-typechecking the patterns,
using the embedded types of dcons and variables if we want to avoid changing
the absyn util the type checker overhaul.]

** Explicit polymorphic abstraction (TFN) in the match code

Derived from the polymorphic type of the match.
Abstraction over "real" typevars, which in turn have been used to "instantiate"
the polytype. This instantiated polytype is what is used as the type argument
to makeAndor.

(also bindings, handler matches need to be treated appropriately)


Note: FNexp, CASEexp, HANDLEexp are all based on a match, represented as

  fnrules = AS.rule list * ty * ty

Here the components are:

  rules : AS.rule list
    -- the actual list of rules (no extra default rule added), each
       rule consisting of a pattern (lhs) and an expression (rhs)
  lhsTy : T.ty 
    -- the common type of the patterns, the "domain" or input type
       of the match

  rhsTy : T.ty
    -- the common type of the rhs expressions, the "range" or output type
       of the match

The lhsTy is needed for match compilation as, for instance, the initial
type argument of makeAndor, which establishes the pattern type and
by deconstruction the types of all the pattern nodes and their associated
(s)vars.

The rhsTy is needed for a rather paticular purpose, to provide the
type to assign to artificial (generated) raise expressions during
match compilation (in particular, passed as an argument to the Failure
function in vmcexp.sml). This rhsTy was just added to the definition
of fnrules in Abysn.  When match compilation (MatchComp.matchComp) is
invoked, this type is passed as an argument and is passed on to
MCCode.code and then to VMCexp.Failure.

[For source occurrences of "raise", the _return_ type, which is
arbitrary, is determined by returning a fresh metatyvar that will
"soak up" the context type through unification. This can't be done for
the occurrences of "raise" _manufactured_ by the match compiler, hence
the need for an explicit passing of the rhsTy.]


================================================================================
[27] External (source) variable binding and RHSs linkage and dispatch
================================================================================

After the decision tree is constructed, we need the following:

For each _occurrence_ of a source variable in a pattern, we need
(1) the rule number of that occurrence (available in vars fields), and
(2) the corresponding internal varialbe (with its type) for that node in the pattern
  space (andor tree)

Then at each LEAF node of the decision tree, we need (during code generation) to add
bindings of the source variables of the chosen rule to the appropriate internal
variables.

We also need to have a count of how many times a rule occurs at a LEAF node of the
decision tree.
  -- if it occurs 0 times, the rule is redundant
  -- if it occurs > 1 times, we need to form a RHS function by abstracting over
     the rule source variables, and at each of its LEAF nodes, we need to
     apply that RHS function to the tuple of corresponding internal variables.
     
Create a mapping from
  (source var, ruleno) to (internal) svar (equivalently the andor path)
  ruleno to set of (source var, path)

What we have in the andor tree is essentially
  path -> (source var, ruleno)  (through the vars and asvars fields)

Another even more useful mapping would be:

  varmap: ruleno -> [(source var, svar), ...]

Could this mapping be constructed (on the side) while makeAndor builds the
andor tree?  Only issue is where a VAR node is constructed first and then another
structured pattern is merged into it, perhaps replacing the svar of the VAR node
with a new one [as in the next to last rule of mergeAndor]. This could be fixed
by _resetting_ the svar field of the node produced by the call of mergeAndor in this
rule.

Otherwise, could do a global post-pass on the entire andor tree to construct this
mapping.

   for each node N:
     for each (v,r) in N.vars: insert(r, (v, N.svar), varmap)   (* destructively? *) 
     for each (v,r) in N.asvars: insert(r, (v, N.svar), varmap)
(this could also be done functionally)

Then when constructing the linkage for a RHS (LEAF) node for rule r, we lookup
r in var map: (v_ext,v_int) then do let-bindings let v_ext = v_int in ...
around the rhs expression.

Or, if the rhs is shared by multiple rules, form

   f = (lambda (v_ext1,...,v_extn) . rhs_exp)

at the dispatch point

   rhs_r = f(v_int1,...,v_intn)

the bindings of the dispatch function f would be wrapped around the body of
the match expression.

NOTE: Each rule introduces its own _local_ bindings of its own pattern variables.
A given variable _name_ may occur in different rules (even with different types!),
but these variables will be unique to each rule.  For example:

fun f (x::y, z) = x + 3 > 0
  | f (nil, x) = not x

Here x in the first rule is of type int, while x in the second rule is a different
locally bound variable of type bool.  So the two "rule variables" (<x>, 0) and
(<x>, 1) involve two different variables, both named x, with types int and bool,
respectively.  The two variables named x will have different lvars (access values).

NOTE: Variables appearing in patterns are _not_ polymorphic (they are
lambda-bound in fun matches), and their occurrences in patterns are not assigned
instances of a polymorphic type. Therefore (?)  the tyvars field of a pattern
VALvar should contain the empty list. The type of a pattern variable may contain
metatyvars introduced by instantiating polymorphic types of datacons.  Those
metatyvars may be "generalized" at the level of a val/fun binding containing
the match that contains the pattern, but they can be treated (after typechecking)
as fixed during the analysis and translation of the match.

================================================================================
[28] "Code generation" (mc-code.sml) Generating the absyn for a match
================================================================================
[Preliminary notes, extracted from mc-code.sml]
----------------------------------------------------------------------------
When we are generating code for a decTree D (at node N), the surrounding
structure for D has been "destructed" to provide a context that, in particular
has a binding for Var(Node(D)).  During dynamic matching, Var(D) will be bound to
the value component being matched to decTree.
 
When an AND node is destructed, we get a Letr binding of all the variables (lvars) of
the component nodes of the AND.  We need to remember that these have been bound
(and are still in scope?) when we need to use one of those variables for some
decision. Their scope os the body of the Letr exp.

So at each subexpression we can keep track of which variables are in scope
at that subexpression (a set of lvars).  Veriables for the nodes of variants
are bound in branches of Case0 expressions.  These are in scope only in the
exp of the corresponding switch branch.

How much of the top of the pattern space has been destructured before we
deal with the first decTree node (OR node), D?  I must be at least enough to
bind Var(Node(D)).  At the top level, the whole value being matched is bound
to vtop.

(1) find root andor node of dtree and construct code to access that node
(2) generate Case0 for root of dtree
    (2a) for each decVariant for that root, "find" arg component corresponding
         to the associated variant decTree (meaning construct access code).

 * Given a decTree node (and associated andor node and its path), need two bind a variable
   to the correspoinding value component (using a nesting of letv bindings).
 * Among the existing variable bindings, which is closest along a path from vtop (the
   root variable bound to the entire argument value) to the path to the target..

 * given a path (of the next decTree node), find the nearest (lowest) variable
   bound along that path and construct access to bind a variable to the given path.

   Example:  decTree D @ p0 where p0 = [k1, k2, k3, k4, k5, k6]
    The case0 code for D must be placed in a mcexp context that "unravels" the
    path p0 and binds a variable v_p0 to the arg value at p0 (val_p0).
    Maybe this is represented as a kind of "continuation", or "context" expression?

    Suppose a variable v is bound at k3 (has path [k1, k2, k3]) and it is the "closest"
    variable on the path, i.e. there are no variables bound at k4, k5, k6.
    Suppose k4, k5, k6 are R1.D(true).R2   (k4 = R1, k5 = D(true), k6 = R2)
    The D(true) key on this path means there has been a previous decTree at the
    path p1 = [k1, ..., k4], with true as one of its keys. The OR node at p1 "dominates"
    the OR node underlying the decTree at  

    letv (v1,v2) = v (the variable at k3)
       Case0 v1
         true =>   (bind a variable here? No, because of nullary key true.)
   
    If 

Example:
AND(a1,a2,a3)
  
let vtop = arg
letv (v1,v2,v3) = vtop
    (v1: R1, v2: R2, v3: R3)

get dtree
dtree.node.path = R1  --> v3 = vtop.R1

    Case0(v1, branches)
    variants = R1.variants = (k1, a11) :: (k2, a12) :: arest
       branch1 = (k1, dt1) :: dtrest1
       k1 => code(a11,dt1)
       branch2 = (k2, dt2):: dtrest2  (where dtrest1 = (k2,dt2)::dtrest2)
       k2 => code(a12,dt2)


what if dt_root (root node of decTree) has path R1.R3?

   letv (v1,...) = vtop
    letv (w1,w2,w3) = v1   (w3 = vtop.R1.R3)
      case0 w3
       etc. ....

auxiliary info

   path -> variable (for already bound variables)
   variable -> path

(for "visible top-and structure")

for each variable binding in the code, can record path for the variable.
 
given a path, can produce a path relative to some existing bound variable

CONJECTURE: if N1 is an ancestor of N2, then Var(N1) is in scope at the
"(code) position" of N2.


================================================================================
[29] Vector patterns
================================================================================
The vector key or con case discriminates on vector length, but that discrimination
does not destructure the vector (i.e. does not "strip" a constructor). Instead,
the vector is left intact and must be destructed explicitly by a nested sequence
of Vector.sub (vector subscript) operations.

* There is no absyn form for vector subscripting (also no syntax form for record
  selection. We could add such forms, or we can create some other kind of
  syntactic representative for record selection and vector subscripting (what
  would that be?).

* When you "virtually" strip the V (VLEN) constructor when discriminating on
  vector length, the resulting "stripped" value is the same vector -- it is not
  turned into a record/tuple. Therefore the children of a vector OR node are
  vectors, and should be represented by (new) vector andor nodes (VEC). When
  the corresponding vector values are deconstructed, it will be done by a
  series of nested lets involving vector subscripting:

    letv (v0, v1, v2) = (sv: ty vector) in body
    ==>
    let v0 = Vector.sub(sv,0) in
      let v1 = Vector.sub(sv,1) in
	let v2 = Vector.sub(sv,2) in body

  (expanded by a "wrapLets" function).

  How do we represent

  (1)    let v1 = Vector.sub(v0, i) in body

  in Absyn?

  For records, we could possibly expand <<select>> into the
  appropriate expansion of #n, i.e. (fn (_,_,_,x,_,_) => x) for
  tuples, but this would not work for vectors, and it would
  reintroduce a (simple) record pattern match that would have to be
  tranlated.

  We could introduce an Absyn for for the primop Vector.sub,
  and another one for record selection. Say

  datatype exp =
    ...
    | selVec of exp * int  (* n >= 0 *)
    | selRec of exp * int  (* n >= 0 *)

  Then the absyn for (1) would be

    let v1 = selVec(v0,i)

  The types would be

    selRec : {f0: t0, ..., fn: tn, ...} * int -> tn

    selVec : ty vector * int -> ty

  The first of these is anomalous, but we don't need to deal with these
  operators during type checking because they do not occur in the surface
  abstract syntax.  Also, during translation, the index of selection/subscripting
  will be known statically, so the type (of a record selection) will be known.

  Alternatively, selRec and selVec could be a pair of "handmade" constants
  (VALvars) that could be inserted in the abstract syntax during match
  compilation, so that 

    val selVec = VALvar{name = <selVec>, ...}
    selVec(v0,i)  ==>  APP(VARexp (selVec,_), NUMexp i)

  and similarly for selRec.

  A related approach would be to add destRec and destVec as new variants of
  VALvar, whose typing and translation would be treated in an ad hoc manner.
  This has the advantage of not needing to construct an artificial and inaccurate
  type for the VALvar form. But the application of these special "variables"
  would have to be detected and handled specially during translation.

* NOTE: This analysis indicates that _converting_ the contents of a vector
  into a tuple (AND node) during match compilation is incorrect. We need to
  preserve the distinction between records/tuples and vectors through match
  compilation and translation.  Therefore we need to add a new VEC node to
  the andor type.

* NOTE: first approach (7/14/20) chosen is to add SelRec and SelVec as
  new variants of VarCon.VALvar.  These will need to be handled
  specially in translate.


================================================================================
[30] Variable bindings (VB); irrefutable patterns; single, irrefutable rules
================================================================================

Defn: a pattern is irrefutable if it will successfully match any value of
 its type.

* An irrefutable pattern is made up of products (records/tuples), variables,
and singleton datacons (with or without arguments): 

Defn: Pattern p is _irrefutable) iff p is constructed by these three constructions:
    (1) p == (p0, ..., pn)  where pi is irrefutable; or
    (2) p == v, a variable (VarCon.var)
    (3) p == Dcon {p}, where p (if present) is irrefutable

Note: These three constructions correspond to the AndOr node constructors
handled by genNode in mc-code.sml.

Defn: a pattern is refutable if it is not irrefutable

* A refutable pattern has a refutable element, which could be

   (1) a constant (int, word, char, string); or
   (2) a nonsingular datacon (e.g. true, false, nil, cons, ...)
       (a datacon belonging to a datatype with more than one datacon); or
   (3) a vector element (AND[VECTOR]) (vector patterns are always refutable)

The refutable elements of (a list of) patterns are the elements that give
rise to OR-nodes in the AndOr tree for the patterns.

An irrefutable pattern has an AndOr tree with no OR nodes (only VAR, AND[RECORD],
and SINGLE nodes).  Note that any vector element gives rise to an OR-node
(of vector type), with variants leading to AND[RECORD] nodes.

If an irrefutable pattern occurs in a list of rules, any rules following the
one with the irrefutable pattern are redundant (unreachable).  The rule with
an irrefutable pattern serves as a default rule (if the earlier patterns are
not exhaustive).

Example:  pats = [(x,y)]

  (0) (x,y)   =>  rhs0     

AndOr: andor(pats)

  [] AND ('X * 'Y)
     [0] VAR (x, 0)
     [1] VAR (y, 0)

Decision Tree:

  DLEAF 0  (trivial, no OR nodes)

Code:

  Letr (sv_x, sv_y) = svroot in rhs0

  == genNode (andor(pats), genDec (DLEAF 0))
     == genNode (andor(pats), rhs0)

Lexp:

  LET lvar_x = SELECT (0, lvar_root) in
    LET lvar_y = SELECT (1, lvar_root) in trans(rhs0)


In the event of there being no OR-nodes, decisionTree will produce the result
DLEAF 0, which genDec will translate to rhs0. genNode (applied to the pattern
AndOr tree, will produce the necessary patten destruction code to wrap around
rhs0.


================================================================================
[31] Translating VB declarations (e.g. val (x,y) = e, or val x::y = e *)
================================================================================

NOTE: We don't need to worry about the "top-level" case -- that should be handled
by the code at the end of the main function transDec in Translate. So we only
need to properly handle the "local" case, which has a _body_ expression.  But
we probably need to get the management of "boundtyvs" (for vbs) and "btvs"
(for VALvars) right so that they will be translated into type abstractions and
applications.

Naive translation:

Example 1: irrefutable pattern, no case

  val (x,y) = def

local decl:

  let val (x,y) = def in body

  ==>

  let r = def in
    let x = SELECT(0,r) in
      let y = SELECT(1,r) in
        body

top-level decl:

  - val (x,y) = def;

  ==>

  local
    let r = def            (* VB [vb_r] *)
  in
    let x = SELECT(0,r)    (* VB [vb_x, vb_y] *)
    let y = SELECT(1,r)
  end

Example 2: refutable pattern

  val x::y = def

local decl:

  let val x::y = def in body

  ==>

  case def
    of x::y => body
     | _ => raise Bind

  let v0 = CASEexp (def, [(cons(vx,vy), (vx,vy)], isBind)   (* isBind = false *)
    in let x = select(v0, 0) in
         let y = select(v0, 1) in
	   body

  [WRONG!]
  let v0 = def in   (* v0 a fresh var = rootvar returned by matchComp *)
    switch v0
      [(cons(sv1), let x = select(sv1,0) in let y = select(sv1,1) in body)]
      SOME (raise Bind)
      

top-level decl: (We don't have to deal with this because Translate.transDec
  takes care of it. All we need is the generic transVB and transVBs functioins.)

  - val x::y = def;

  ==>

  local
    let r = def    (* VB [vb_r] *)
  in
    val (x,y) = 
      case r
        of ::(u,v) => (u,v)
	{{ | nil => raise Bind }}  (* one rule, bindExn default *)
  end

  local
    val r = def  (* r a fresh var *)
    val d =      (* cons destruct of r; d a fresh var *)
      CASEexp(VARexp(ref r, tvs???),
              [(cons(x,y), (x,y))]
	      bindExn)
      -->
      switch r
        [(cons(v), VAR v)]
	SOME (raise Bind)   (* may raise Bind *)
  in
    val x = select(d,0)
    val y = select(d,1)
  end


* What about a declaration that is part of a sequence of declarations?

Example 3: (local) 

  let
    val a = 3       (* VB [vb_a, vb_xy, vb_p] *)
    val x::y = e
    val p = e'
  in body

we could preprocess this into a nested sequence of lets:

  let val a = 3 in
    let val x::y = e in
      let p = e' in
        body

Then the second let would be expanded as above.

Similarly for 1st decl in local?

--------------------------------------------------------------------------------
Here is the pseudo-code for transVB:

transVB( VB{pat, exp, boundtvs, ...}, body) >>
  1. If pat is a simple variable pattern v (VARpat, with or without type constraint),
     then "Let v = exp in body" (with something to deal with polymorphism of exp?).
  2. For general, compound pat:
     a. patvars = variables in pat (in some order, e.g. left to right)
     b. patvarstuple = and expression creating a tuple of the patvars values
     c. matchComp ([RULE(pat, patvarstuple)], ...):
        ==> (matchExp, rootvar) 
        This match will destruct the exp (value) to build the tuple of pattern
	variable values.  
     d. Let rootvar = exp in matchexp  ==> tuple of var values
        This causes the exp value to be destructed by matchexp, yielding the
	tuple of pattern variable values.
     e. wrapLets(patvars, 0, body)
        wraps the body in a sequence of let bindindings that bind the original
	pattern variables with the corresponding components of patvarstuple
     f. Bind the variable tuple to a new var, and execute e:
        let newvar = (let rootvar = exp in patvarstuple) in wrapLets(patvars, 0, body)

Missing details?  How to preserve and propagate information about polymorphic
types of the pattern variables, which may be instantiated where they occur in body.
-- Is the existing tyvar annotation of the variables enough?
-- What is mkPE doing? Do we need a corresponding transPolyExp?
-- This problem may be handled more clearly and systematically once we have
   a fully explicit typed absyn. (after type-checker rewrite)

CLAIM: We don't need to treat irrefutable bindings specially, since
the special case will be produced automatically by the *code* function
(i.e., one rule, no default, destructing and variable binding).

Should we try to unify the treatment of local decls and top-level
decls by applying the same decl -> decl translation to both?  Or
does the tranlation need to distinguish the local and top-level
cases?


NOTE: It may be possible to "restore" use of source variables (in
mc-code.sml) by mapping (some) SV.svars back to V.vars using the
ruleVarMap for a given rule (a bijection between source variables in
the rule pattern and a subset of internal svar variables.  At some
point, this could be used to "map back" from svars to corresponding
vars.  This could at least partially eliminate the need for Letm.  The
trick is to figure out the right place to do this.


================================================================================
[32] RHS linkage; direct or via rhs functions
================================================================================

For direct linkage, for single-use rules, we use Letm to match up
the V.vars that appear in the rhs expression with the corresponding
svars (which were collected from the ruleVarMap (MCcode.code; mc-code.sml)).

We leave the vars occurences in the rhs expression alone (instead of
"alpha converting" them to the corresponding svars.  We can't go back
and retrofit the vars into the andor/decisiontree/mcexp, since a given
svar (representing a pattern point) will in general be shared among
several rules (and possibly be "equivalenced" with several different
source vars in those rules - or even with multiple source vars in a
single rule, because of patterns like "x as y").  So we can't unify
the vars and svars by replacing svars by vars (and of course some
svars don't have equivalent vars anyway).

QUESTION: What if we, during match code generation (MCCode.code), agressivly
replaced svar binding (and applied) occurrences in the generated code by
matching vars when available -- but this would only make sense in the
context of a particular rule, since the var <-> svar mapping is per rule.
Is the rule known and well-defined when we are making the svar bindings?

================================================================================
[33] TransMatch: translating matches in an Absyn to Absyn transformation
================================================================================
The "compilation" or translation of matches (case, handle, binding flavors) needs
type information, or at least is most natural to perform in the presence of types.
This means that we can't do it before type checking, in the basic elaboration
phase. It also doesn't work to tie match compilation in with type checking, since
with the interleaving of typing and match compilation it is impossible (or at least
difficult, to guarantee that the desired type information is produced before needed
in match compilation.  So the cleanest approach is to do match compilation in
a separate post-type-checking phase that we call transmatch (structure TransMatch).
With this approach, the input is fully typed absyn (though it would be more
convenient if it were fully _explicitly_ typed).

This translation preserves the absyn except for the small number of constructs
where matches are to be "compiled".  The case and handle constructs are fairly
straightforward because there is no tricky interaction with polymorphism.  The
valbind case, where polymorphism is produced, is trickier (see transVB). The
issue is producing absyn that the translation phase (translation to Plambda.lexp)
can deal with properly.

================================================================================
[34] Polymorphism: representing and maintaining it when translating val bindings
================================================================================
The relevant functions in the old translator are mkVB (translating vbs) and
mkPE (translate an expression with potential type parameters, i.e. a polymorphic
expression on the rhs of a binding).

The main problem seems to be to coordinate between the polymorphism arity (btvs)
of a variable (a pattern variable in the decl) defined as a selection from a
tuple bound to another polymorphic variable of a different arity (boundtvs).
Can we get away with just considering the btvs lists of the two variables, perhaps
using the assumption that the btvs metatyvars are a subset of the boundtvs
metatyvars, which is actually the case in the translation of a VB.  Is this
a coincidence that won't work in general? (But maybe it doesn't need to work
in general?)

OBSERVATION: The btvs of a pattern variable is a subset of the boundtvs of
the entire pattern.  The btvs's of the pattern variables may overlap, but
the union of their btvs will be equal to the pattern boundtvs stored in the
VB record.

For a particar pattern variable getting a polymorphich type, the polymorphic
abstraction should be done over the btvs of the VALvar, which is a reference
set by TypeCheck.generalizeTy.  A variable bound to the pattern variable tuple
would be polymorphic over the union of btvs of the pattern variables, which
should be the same as the VB boundtvs.

The rebindings of the pattern variables themselves (transVB.wrapLets) should
re-establish the polymorphism of those variables when translated.

NOTE: for the call of MC.matchComp in transVB, the VB record must be modified
by adding a typ field (to be defined by the type checker). This type will be
the common type of the pattern and the rhs expression. [This type could be
reconstructed, essentially by calling the type checker again on the pattern,
but that was done already -- why not just store the result for later use?]

There are two flavors of VB:

(1) _administrative_ VB used in _administrative_ lets, say within the
expressions produced by match compilation for case and handle constructs.

(2) _polymorphic_ VB associated with valbind declarations.

These may be (partly) differentiated by the fact that administrative
valbinds are not meant to introduce polymorphism, and therefore will always
have boundtvs = nil.  Other non-administrative valbinds may also have
nil boundtvs, simply because there is no polymorphism in the binding
(e.g. val x = 3).

So the question is how the polymorphic nature of some valbinds is
preserved by match compilation. We need to judiciously use VB with
non nil boundtvs. Generally, these will be simple VBs, with the binding
pattern being a single variable. The btvs of that variable will indicate
the degree of polymorphism (arity of TFN).  But in applied occurrences,
those variables will then need type arguments (TAPP args).  How do
we compute these type arguments.  An example is displayed in the old
Translate mkVB function (inside of mkVBs).

Is there a general approach to calculating TFNs and the corresponding
TAPPs, or is it a set of ad hoc situations like the selections produced
by mapLets in transVB?  Hopefully this will be clearer when we have
fully explicit typing of absyn, where these type abstractions and applications
will be spelled out in the abstract syntax.

OBSERVATION: After match compilation (transMatch), all LETexp valbinds
have a single variable pattern.  A subset of these (from source VBs) will
involve polymorphism, but the polymorphic variable will be unique, since
compound patterns have been compiled away (by transVB).


================================================================================
[35] OR patterns
================================================================================
As a first approximation we interatively merge the two patterns:

[src]

      | mergeAndor (ORpat(pat1,pat2), ty, rule, rpath, andor) =
	mergeAndor(pat1, ty, rule, rpath,
		   mergeAndor(pat2, ty, rule, rpath, andor))

This doesn't work because, for example, in the following test case (t16.sml)

[src]
    datatype t = A of int * int | B of int * int;

    fun f (A(x,y) | B(x,y)) = x + y;

the pattern-bound variables x and y get duplicated, and the duplicates have
different associated svars that they should bind to.  There will be a single
rhs function for this rule (rule 0 in this example), but it should be applied
two different pares of svars in the two branches of the code (branching on
A/B) where it is called.  The absyn produced by match compiling should look
something like:

    let val rhsfun0 [lv31] =
	      (fn SfunArg [lv32] =>
		    let val y [lv20] = #0 SfunArg [lv32] in
		      let val x [lv21] = #1 SfunArg [lv32] in
			Int.+ (x [lv21],y [lv20])  (* rhs *)
		    end end)
    in SWITCH <> [lv24]
	  of B <B> [lv25] =>   (* B branch with svar <B>, lvar 25 *)
	       let val <B.0> [lv26] = #0 <B> [lv25] in  (* y svar *)
		 let val <B.1> [lv27] = #1 <B> [lv25] in (* x svar *)
		   rhsfun0 (<B.1> [lv27], <B.0> [lv26])
	       end end
	   | A <A> [lv28] =>   (* A branch with svar <A>, lvar 28 *)
	       let val <A.0> [lv29] = #0 <A> [lv28] in  (* y svar *)
		 let val <A.1> [lv30] = #1 <A> [lv28] in  (* x svar *)
		   rhsfun0 (<A.1> [lv30], <A.0> [lv29])
	       end end
    end

[BUG: Right now, 2020-8-18, 4 arguments are being passed to rhsfun0, two copies
of x (from A and B branches) and two copies of y (from A and B branches), but
only two of those argument variables are bound in each of the two calls.]

When generating the branches of this switch, how do we know which versions
of x and y should be bound and used in each branch?

We assume (Elabcore.elabPat) that a single version of each pattern variable is
used in both the patterns in an OR pat.  This is, in the above example, the
x in A(x,y) is the same (or equivalent) VALvar as the x in B(x,y), with the same
lvar. ** Check that this property is ensured by elabPat. **

Currently we reconstruct the mapping from source vars to administrative svars
for each rule using a separate pass over the andor tree (RuleVarMap.makeRuleMap).

We could capture this mapping while constructing the andor tree. I.e. for any
VARpat pattern we could register the mapping from its var to the svar for this
node.  But in the case of the OR pattern above, we would be registering x and
y twice, with different svars.  How to we distinguish between these svar
bindings in MCCode.genRHS?  Note that the rule number is not useful for
distinguishing these cases since there is only one rule number involved
(e.g. 0 in this case).

IDEA: associate a path with each var -> svar binding, and at a terminal genRHS
at path P, pass only those var bindings that are "compatible" with P. This should
filter out bindings belonging to another branch of the decision tree.

A binding therefore is logically a tuple or relation involving 4 components:

   (1) rule -- the rule the variable occurs in
   (2) var  -- the source variable (var)
   (3) path -- the path that determines the pattern node where the variable occurs
   (4) svar -- the svar (internal adiministrative variable) that var should bind to

Because of OR patterns, a source variable x may have multiple occurrences in
the pattern of a given rule. For a given RHS invocation, there should be only
one version (occurrence) of x passed to the RHS function.

For a given rule (and hence RHS), we will have a mapping var -> svar * path,
and we pass only those svars where the path is compatible with the RHS path.

This mapping could be constructed like the ruleVarMapping by a post-traversal
of the andor tree, or it could be constructed during the construction of the
andor tree, but that may be more complicated.

CHANGES: 
(1) In RuleVarMap (matchcomp/varmap.sml), add path to the (var,svar) list
for each rule. So rulemaps are ruleno -> (var * path * svar) list.

Example [35.1]:

  datatype t = A of t * t | B of t * t | L of int;

  fun f ( A( ( A(L x, L y) | B(L x, L y) ), L 2 ) | B (L y, L x) ) = x + y;

3 versions of the variable pair (x,y), at "decision" paths A.A, A.B, B.
(1) x @ <A.0.A.0.L>, y @ <A.0.A.1.L>
(2) x @ <A.0.B.0.L>, y @ <A.0.B.1.L>
(3) x @ <B.1.L>, y @ <B.0.L>
[all at rule 0]

andor:
[<>] OR v26 {0} {}
   B [<B>] AND v27 {0} {}
      [<B.0>] OR v28 {0} {}
         L [<B.0.L>] VARS v29 (y,0) {0}
      [<B.1>] OR v30 {0} {}
         L [<B.1.L>] VARS v31 (x,0) {0}
   A [<A>] AND v32 {0} {}
      [<A.0>] OR v33 {0} {}
         B [<A.0.B>] AND v34 {0} {}
            [<A.0.B.0>] OR v35 {0} {}
               L [<A.0.B.0.L>] VARS v36 (x,0) {0}
            [<A.0.B.1>] OR v37 {0} {}
               L [<A.0.B.1.L>] VARS v38 (y,0) {0}
         A [<A.0.A>] AND v39 {0} {}
            [<A.0.A.0>] OR v40 {0} {}
               L [<A.0.A.0.L>] VARS v41 (x,0) {0}
            [<A.0.A.1>] OR v42 {0} {}
               L [<A.0.A.1.L>] VARS v43 (y,0) {0}
      [<A.1>] OR v44 {0} {}
         L [<A.1.L>] OR v45 {0} {}
            I2 LEAF {0} {}

dectree:
CHOICE [<>]
  B CHOICE [<B.0>]
    L CHOICE [<B.1>]
      L DLEAF 0  <B>, <B.0.L>, <B.1.L>   -- dtrace for DLEAF
                 <B.0.L> ~ x, <B.1.L> ~ y      longest common prefix : <B>
                 <A.0.A.0.L> ~ x : lcp: <>
      * MATCH    <B>, <B.0.L> <B.1.~L>    [ B(L *, ~L) ]
    * MATCH      <B>, <B.0.~L>            [ B(~L, *) ]
  A CHOICE [<A.1>]
    L CHOICE [<A.1.L>]
      I2 CHOICE [<A.0>]
        B CHOICE [<A.0.B.0>]
          L CHOICE [<A.0.B.1>]
            L DLEAF 0  <A>, <A.1.L> <A.0.B>, <A.0.B.0.L> <A.0.B.1.L>   -- dtrace for DLEAF
	               <A.0.B.0.L> ~ x,  <A.0.B.1.L> ~ y   longest common prefix: <A.0.B>
                       <B.1.L> ~ x  longest common prefix: <>
		       <A.0.A.0.L> ~ x  longest common prefix  <A.0>
            * MATCH (~L)
          * MATCH (~L)
        A CHOICE [<A.0.A.0>]
          L CHOICE [<A.0.A.1>]
            L DLEAF 0  <A>, <A.1.L>, <A.0.A.0.L>, <A.0.A.1.L>   -- dtrace for DLEAF
	               <A.0.A.0.L> ~ x,  <A.0.A.1.L> ~ y   longest common prefix: <A.0.A>
            * MATCH (~L) [<A.0.A.1.~L>]
          * MATCH (~L) [<A.0.A.0.~L>]
        * MATCH (~A,B -> L)  <A.0.B.0.L>
      * MATCH (~I2)  [<A.1.L.~I2>]  [ A(*, L(~I2)) ]
    * MATCH (~L)  [<A.1.~L>]  [ A(*, (~L) *) ]
  * MATCH (~A,B -> L)  [<L>]  [ L * ]

>>>makeRuleMap
I: y[22] ==> <B.0.L>[29]
I: x[23] ==> <B.1.L>[31]     -- B
I: x[23] ==> <A.0.B.0.L>[36]
I: y[22] ==> <A.0.B.1.L>[38] -- A.0.B  = lcp (<A.0.B.0.L> and <A.0.B.1.L>)
I: x[23] ==> <A.0.A.0.L>[41]  
I: y[22] ==> <A.0.A.1.L>[43] -- A.0.A
<<<makeRuleMap

let val rhsfun0 [lv46] =
          (fn SfunArg [lv47] =>
                let val y [lv22] = #0 SfunArg [lv47]
             	 in let val x [lv23] = #1 SfunArg [lv47]
              	     in let val y [lv22] = #2 SfunArg [lv47]
                         in let val x [lv23] = #3 SfunArg [lv47]
                             in let val x [lv23] = #4 SfunArg [lv47]
                                 in let val y [lv22] = #5 SfunArg [lv47]
                                     in Int.+ (x [lv23],y [lv22])
                end end end end end end)
in (SWITCH <> [lv26]
      of B <B> [lv27] =>
           let val <B.0> [lv28] = #0 <B> [lv27]
            in let val <B.1> [lv30] = #1 <B> [lv27]
                in (SWITCH <B.0> [lv28]
		      of L <B.0.L> [lv29] =>
		           (SWITCH <B.1> [lv30]
			      of L <B.1.L> [lv31] =>
			         rhsfun0  (* too many args *)
				    (<A.0.A.1.L> [lv43], <A.0.A.0.L> [lv41],
				     <A.0.B.1.L> [lv38], <A.0.B.0.L> [lv36],
				     <B.1.L> [lv31], <B.0.L> [lv29])
                               | _ => raise Match)
                         | _ => raise Match)
           end end
       | A <A> [lv32] =>
         let val <A.0> [lv33] = #0 <A> [lv32]
          in let val <A.1> [lv44] = #1 <A> [lv32]
              in (SWITCH <A.1> [lv44]
                    of L <A.1.L> [lv45] =>
                         (SWITCH <A.1.L> [lv45]
			    of I2 =>   (* int const 2 *)
                               (SWITCH <A.0> [lv33]
                                  of B <A.0.B> [lv34] =>
				     let val <A.0.B.0> [lv35] = #0 <A.0.B> [lv34]
				      in let val <A.0.B.1> [lv37] = #1 <A.0.B> [lv34]
				          in (SWITCH <A.0.B.0> [lv35]
					        of L <A.0.B.0.L> [lv36] =>
						     (SWITCH <A.0.B.1> [lv37]
						        of L <A.0.B.1.L> [lv38] =>
							     rhsfun0 (<<the 6 variables>>)
                                                         | _ => raise Match)
                                                 | _ => raise Match)
                                         end 
                                     end
				   | A <A.0.A> [lv39] =>
                                     let val <A.0.A.0> [lv40] = #0 <A.0.A> [lv39]
                                      in let val <A.0.A.1> [lv42] = #1 <A.0.A> [lv39]
                                          in (SWITCH <A.0.A.0> [lv40]
                                                of L <A.0.A.0.L> [lv41] =>
                                                     (SWITCH <A.0.A.1> [lv42]
                                                        of L <A.0.A.1.L> [lv43] =>
                                                             rhsfun0 (<<the six variables>>)
                                                         | _ => raise Match)
                                                 | _ => raise Match)
                                         end
                                     end
                                   | _ => raise Match)
                             | _ => raise Match)
                     | _ => raise Match)
             end
         end
       | _ => raise Match)
end

Algorithm:
At a RHS node for rule n (DLEAF n). Get the decision tree branch for this DLEAF
decision tree node, say [p0, ..., pk] (the paths at decision points on the dt branch).

Given a set of variable-path pairs (v,p), and the decision tree branch
[p0, ..., pk], calculate the longest common prefix of p with
p0, ..., pk, call it lcp.  Choose all variables v such that lcp is maximal for binding

Claim 1: each chosen v is "in scope" for the DLEAF (RHS dispatch).

Claim 2: Any "in scope" variable occurrence (v, p) will have the maximal length lcp
with the branch.
-----------------------

This attempt didn't work (or wasn't chosen). Instead, instriment decision trees
with "traces", which are lists of paths, where the path designates the choice
points (including the choice) along a maximal branch of the decision tree, i.e.
a branch terminating in DMATCH or DLEAF.  At a DLEAF terminal node where we
dispatch to a RHS, the trace to that node is used to determine which source
variables (vars) are "consistent" with the choices in the trace, and only
consistent variables are "bound" for that RHS.  See MCUtil.consistentPath for
definition of "consistency" used.


================================================================================
[36] Unique bound lvars and lvar alpha-conversion
================================================================================
The fcontract optimization phase (FLINT/opt/fcontract.sml) appears to require
the property that lvar bindings are unique, i.e. that the same lvar is not bound
more that once (even in separate nonoverlapping scopes).  t21.sml is an example
that fails because it does not have this property.

To ensure that lvars are unique, it seems that the whole algorithm involving
the interaction of matchComp and transMatch needs to be done "top-down" rather
than "bottom-up" (as it is initially done). This is so an lvar environment can
be passed down from an lvar binding point to the "match subexpressions" that may
use that lvar (or var/svar having that lvar as access). This environment can
map "original" lvars arrising from the svars of the AND-OR tree to new
"alpha-converting" lvars.

A bottom up approach that tries to alpha-convert the exp produced by
transMatch+matchComp would be very expensive, since lower level subexpressions
would have to be alpha-converted repeatedly as higher-level lvar bindings
are discovered.

The top-down approach means that transMatch and matchComp need to be
mutually recursive, passing an lvar env down through the recursive calls.

** SOME INVARIANTS **

* At a DLEAF node, DLEAF (r, trace), the set of variables available in the
varenvMC at that node is exactly the set of variables in the pattern for r.
This is also the domain of the varenvMC available at this node.

* Each of these variables has exactly one svar for this rule in the
current varenvMC (and the corresponding path is consistent with the trace).


================================================================================
[37] OR pattern validation/normalization
================================================================================

Here are some examples of "funny" OR patterns:

(1)   OR(x, x)     "x | x"
(2)   OR((x,true), (x, y))   "(x,true) | (x, y)"
(3)   OR(x, 1::x)  "x | 1::x"

== OR Normalization: a normalized OR pattern OR(p1,p2) is one where p1 and p2 are
incompatible at their roots.

We can reduce OR patterns to either (1) a non-OR pattern, or (2) a normalized
OR pattern:

(i)    OR(x,x)  ==>  x    -- the OR is eliminated

(ii)   OR((p1,p2), (q1,q2)) ==> (OR(p1,q1), OR(p2,q2)) (for tuples and records)

So (2) normalizes to (x, OR(true, y)).

(iii)  OR(p, x) ==> x;   OR(x, p) ==> x   -- the OR is eliminated

For (iii), consider

   OR(x, 2::x)

This is ambiguous (at least partly).  The nil value would match only the
first pattern x, while [2,3] would match both sides.  For [2,3], the
resulting binding of x could be either x -> [2,3] or x -> [3]. A reasonably way
of resolving the ambiguity is to have the variable x dominate 2::x and reduce
or normalize the OR pattern to x.  Similarly for OR(2::x, x).

Goal: an OR pattern should translate to an OR node in the AND-OR tree.  The
two patterns should therefore split/conflict at their top nodes. Or, in other
words, the two patterns p1 and p2 should generate an OR-node andor tree.  We can
push OR down through product patterns and eliminate it if one of the patterns
is a variable.

Example:

      OR((x,true), (x, y))   "(x,true) | (x, y)"
      ==> (OR(x,x), OR(true,y))
      ==> (x, y)

------------------------------------
== OR pattern checking or validation

Rather than "normalizing" OR patterns to remove undesired examples, we can establish
criteria for "legal" OR patterns and generate error message when an illegal OR pattern
is detected.  Here is a proposal for the desired properties that a legal OR pattern
must satisfy:

An OR pattern OR(p1,p2) is legal if:

(1) p1 and p2 have the same type ty, which is also the type of the OR pattern.

(2) p1 and p2 must have the same set of bound pattern variables, i.e.,
FV(p1) = FV(p2).

(3) p1 and p2 must be _disjoint_, where

Definition: Patterns p1 and p2 are _disjoint_ if no value matches p1 and p2, i.e.
Val(p1) \intersect Val(p2) = \emptyset, where V(p) is the set of values matching p.

Algorithmically, we can test whether p1 and p2 are disjoint by

(1) p1 and p2 are product patterns and there exists a field f such that p1.f and p2.f
are disjoint.

(2) p1 and p2 are sum patterns whose top tags (keys, constructors) are different.
E.g. 1 | 2;  true | false;  nil | p::q

(3) if p1 or p2 is a variable, then they are not disjoint

Conjectured proposition:

Defn: Pattern conjunction. The conjunction of patterns p1 and p2, denoted p1 & p2,
is a pattern which is matched by values matching both p1 and p2.  Thus
Val(p1 & p2) = Val(p1) & Val(p2).

Prop. If p1 and p2 are not disjoint, then there exists a pattern p such that
Val(p) = Val(p1) \intersect Val(p2) = Val (p1 & p2). ("meet" in pattern space).

Actually, this proposition is probably not true.  Counterexample?

Also there is the relation p1 < p2, such that Val(p1) \subset Val(p2) -- any value
matching p2 also matches p1.  A variable is a maximal pattern by that ordering.
(p1 and p2 assumed to be of the same type).

Question: Find two patterns p1 and p2 such that p1 and p2 are not disjoint, but
neither p1 < p2 nor p2 < p1 holds.

Do patterns form a lattice under <?


================================================================================
[NN] Literature
================================================================================

1. Cardelli, "Compiling a Functional Language", L&FP 1984, Section 5: Pattern Matchng
Describes technique credited to MacQueen & Kahn and used in Hope 1980 [check code!].
Rows of patterns broken down into columns .... Heuristics for choosing columns to
analyze next.

2. Augustsson, "Compiling Pattern Matching", ?, 1985
Describes pattern matching as implemented in LML (Lazy ML).

n. Sestoft, "ML Pattern Match Compilation and Partial Evaluation", ?, ?

================================================================================
[0] High level overview of the new match compiler [email to Bob, 2020.5.31]
================================================================================

I am trying to reconstruct the match compilation algorithm from first
principles (after having spend way too much time trying to reverse
engineer the existing (Bill Aitken) code).  The reverse engineering,
while slow and painful, was one way to come to grips with the
essential ideas.  I have been writing lots of notes as I gradually
understand what is going on.  One simple way of thinking of the
problem is that any “pattern-matchable” type (a type with outer layers
of concrete product/sum structure, plus a few primitive types with
constants allowed in patterns, i.e. int, work, char, string) has an
associated “pattern space” that can be represented as a (potentially
infinite) tree which is obtained by unrolling the concrete structure
(abstract types and function types are “atomic” for this purpose).  A
particular pattern is a finite “initial segment” (prefix-closed set of
paths) in this pattern space, and a set of patterns can be
characterized by the union of the initial segments for the patterns.
This union gives one an AND-OR tree (AND for product nodes, OR for sum
nodes corresponding to datatypes or “open” patternable types like int,
string, exceptions (with unbounded numbers of alternatives).  For
engineering/algorithmic purposes you need to annotate this AND-OR tree
with additional information (which bits come from which patterns,
which patterns are “live” or compatible at a given point in the
pattern space, and what kind of “defaulting” is introduced by
occurrences of variables in the patterns. [This AND-OR representation
evolved from an earlier “matrix” view of a pattern sequence that has
been used in lots of formulations — I wrote one up in May, 1084 for
the first time.  The formulating the pattern space as a tree was also
partly inspired by Milner’s Webs note.]

Having constructed the AND-OR tree to concretely represent the pattern
space, the next step is to order the “accessible” (non-nested) OR
nodes by some heuristic criteria and from this ordering (roughly)
construct a decision tree using all the “relevant” choices represented
by the OR nodes.  Once you “choose” an OR node to be the next choice
on a branch of the decision tree, the AND-OR structure beneath its
children (variants), if any, is opened up and introduces new available
OR nodes for including in the decision tree.  When you have used up
the “relevant” OR nodes, you have the complete decision tree.

The final step is to flatten the decision tree into (pseudo) code
(e.g. abstract syntax or FLINT plambda). You have to deal with types
and type variables if the code is typed.  Another engineering
challenge is to try to avoid duplicating the switch code because of
the branching structure of the decision tree, where an single OR node
in the static AND-OR representation might be replicated under the
branches of another OR node.

There are various optimality criteria that may be used to drive the
building of the decision tree, such as total code size, minimizing the
number of tests (switches), etc.  At the very least, there will be no
redundant tests performed dynamically (any given OR node from the
AND-OR tree will be represented at most once on any branch of the
decision tree).  The underlying fundamental idea is not to forget any
information derived from a test so that the test might need to be
performed again somewhere down the line.

So that is a capsule summary of my current approach.  There are lots
of variations.  For instance, there are “backtracking” pattern
matchers that same on code size at the expense of having to repeat
tests.

So far, as I said, I’ve been reconstructing this from first
principles.  Before writing this up (as a very tardy follow up to
Baudinet and MacQueen, 1985), I’ll need to review the literature (see
SML-history/Implementation/pat-match) to see what wheels I have
re-invented.

================================================================================
